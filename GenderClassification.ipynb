{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A very simple model to predict the gender from an image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial setup\n",
    "###  Import\n",
    "Import the required libraries.    \n",
    "For this particular notebook, we are using python 3.8.3, sklearn 0.23.1, and cv2 4.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data reading and processing\n",
    "1. Open the images from the folder in gray scale\n",
    "2. Resize it to 100 * 100\n",
    "3. Apply adaptive histogram equalization. Refer https://docs.opencv.org/master/d5/daf/tutorial_py_histogram_equalization.html\n",
    "4. Return an array of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename),0)\n",
    "        img = cv2.resize(img,(100,100))\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        img = clahe.apply(img)\n",
    "       # img = cv2.equalizeHist(img)\n",
    "        if img is not None:\n",
    "            #print(img.shape)\n",
    "            images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImages(images,num):\n",
    "    fig = plt.figure()\n",
    "    for n in range(num):\n",
    "        ax = fig.add_subplot(1, num, n+1)\n",
    "        imgplot = plt.imshow(images[n],cmap='gray', vmin=0, vmax=255)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImagesFromIndexes(images,indexes):\n",
    "    fig = plt.figure()\n",
    "    num =63\n",
    "    i = 1\n",
    "    rows = 8\n",
    "    cols = 8\n",
    "    axes=[]\n",
    "    fig= plt.figure(figsize = (20,20))\n",
    "    \n",
    "    a = 0\n",
    "    for idx in indexes:\n",
    "        axes.append( fig.add_subplot(rows, cols, a+1) )\n",
    "        a = a + 1\n",
    "        imgplot = plt.imshow(images[idx],cmap='gray', vmin=0, vmax=255)\n",
    "    fig.tight_layout()    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert image to 1D vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertImages2Features(images, label):\n",
    "    #man = 0, woman = 1\n",
    "    x = np.empty((0,10000), int)\n",
    "    for img in images:\n",
    "        #convert 2d to 1d\n",
    "        row = img.shape[0]\n",
    "        col = img.shape[1]\n",
    "        img_1d = img.reshape(1, row*col)\n",
    "        x = np.append(x,img_1d, axis=0)\n",
    "    y = np.full((x.shape[0],1),label)\n",
    "    return x,y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data\n",
    "1. Find mean and standard deviation for the train dataset and store them in suitalble variables for further use\n",
    "2. Normalize the training dataset using the above calculated mean and std dev\n",
    "3. To normalize validation and test dataset, use the mean and std dev from step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeFeatures(x):\n",
    "    mean = np.mean(x, axis = 0)\n",
    "    x = x - mean\n",
    "    std_dev = np.std(x, axis = 0)\n",
    "    x = x/std_dev\n",
    "    return x, mean, std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeFeaturesWithMean(x, mean, std_dev):\n",
    "    x = x - mean\n",
    "    x = x/std_dev\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To check accuracy for predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(y_pred, y_true):\n",
    "    comp = np.zeros(y_pred.shape)\n",
    "    comp[y_pred == y_true] = 1\n",
    "    total_items = y_pred.shape[0]\n",
    "    correct_items = np.sum(comp)\n",
    "    return correct_items/total_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "\n",
    "### Loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_man_train = loadImages(\"/home/sakshi/projects/ML/gender_classification/data/dataset1/train/man\")\n",
    "images_woman_train = loadImages(\"/home/sakshi/projects/ML/gender_classification/data/dataset1/train/woman\")\n",
    "images_man_cv = loadImages(\"/home/sakshi/projects/ML/gender_classification/data/dataset1/valid/man\")\n",
    "images_woman_cv = loadImages(\"/home/sakshi/projects/ML/gender_classification/data/dataset1/valid/woman\")\n",
    "images_man_test = loadImages(\"/home/sakshi/projects/ML/gender_classification/data/dataset1/test/man\")\n",
    "images_woman_test = loadImages(\"/home/sakshi/projects/ML/gender_classification/data/dataset1/test/woman\")\n",
    "#show_images(images_woman, 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to 1D vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_man_train, Y_man_train = convertImages2Features(images_man_train, 0) \n",
    "X_woman_train, Y_woman_train = convertImages2Features(images_woman_train, 1)\n",
    "X_man_cv, Y_man_cv = convertImages2Features(images_man_cv, 0) \n",
    "X_woman_cv, Y_woman_cv = convertImages2Features(images_woman_cv, 1)\n",
    "X_man_test, Y_man_test = convertImages2Features(images_man_test, 0) \n",
    "X_woman_test, Y_woman_test = convertImages2Features(images_woman_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.append(X_man_train, X_woman_train, axis = 0)\n",
    "Y_train = np.append(Y_man_train, Y_woman_train, axis = 0)\n",
    "X_cv = np.append(X_man_cv, X_woman_cv, axis = 0)\n",
    "Y_cv = np.append(Y_man_cv, Y_woman_cv, axis = 0)\n",
    "X_test = np.append(X_man_test, X_woman_test, axis = 0)\n",
    "Y_test = np.append(Y_man_test, Y_woman_test, axis = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A little preprocessing\n",
    "It is important to shuffle the dataset for better traing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-9b80ad67bfe8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mappend\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml_scifit/lib/python3.8/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   4691\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4692\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4693\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)"
     ]
    }
   ],
   "source": [
    "train = np.append(X_train, Y_train, axis = 1)\n",
    "val = np.append(X_cv, Y_cv, axis = 1)\n",
    "\n",
    "np.random.shuffle(train)\n",
    "np.random.shuffle(val)\n",
    "\n",
    "X_train = train[:, 0:train.shape[1]-1]\n",
    "Y_train = train[:, train.shape[1]-1]\n",
    "\n",
    "X_val = val[:, 0:val.shape[1]-1]\n",
    "Y_val = val[:, val.shape[1]-1]\n",
    "\n",
    "print(\"training: X shape = \", X_train.shape, \", Y shape = \", Y_train.shape)\n",
    "print(\"first 10 values of y: \", Y_train[0:10])\n",
    "print(\"Validation: X shape = \", X_val.shape, \", Y shape = \", Y_val.shape)\n",
    "print(\"first 10 values of y: \", Y_val[0:10])\n",
    "print(\"testing: X shape = \", X_test.shape, \", Y shape = \", Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, mean, std_dev = normalizeFeatures(X_train)\n",
    "X_cv = normalizeFeaturesWithMean(X_cv, mean, std_dev)\n",
    "X_test = normalizeFeaturesWithMean(X_test, mean, std_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principle Component Analysis\n",
    "We will be reducing the dimensions for the input feature vector using Principle Component Analysis(PCA) by retaining 95 % variance.    \n",
    "Refer https://www.datacamp.com/community/tutorials/principal-component-analysis-in-python for better understanding.     \n",
    "P.S. fit_transform will take a bit longer for execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(0.95) # causes overfitting\n",
    "#pca = PCA(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "458"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "principalComponents = pca.fit_transform(X_train)\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_train = pca.transform(X_train)\n",
    "X_pca_cv = pca.transform(X_cv)\n",
    "X_pca_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model\n",
    "Hyperparameters: C, Gamma    \n",
    "Kernal: rbf    \n",
    "When I trained the model initially, the model was biasd. So, I added up the class weights.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C =  10 , Gamma =  0.001 : training accuracy =  0.9997054491899853 , val accuracy =  0.4852941176470588\n"
     ]
    }
   ],
   "source": [
    "C = [10]\n",
    "Gamma = [0.001]\n",
    "\n",
    "training_accuracies = list()\n",
    "val_accuracies = list()\n",
    "#cw = {0:0.5,1:0.5}\n",
    "\n",
    "best_model = None\n",
    "best_val_accuracy = 0.0\n",
    "\n",
    "for c in C:\n",
    "    ta = list()\n",
    "    va = list() \n",
    "    \n",
    "    for gamma in Gamma:        \n",
    "        \n",
    "        clf = svm.SVC(C = c, gamma = gamma, kernel = \"rbf\",probability = True)\n",
    "        clf.fit(X_pca_train, Y_train.ravel())\n",
    "        \n",
    "        y_pred_train = clf.predict(X_pca_train)\n",
    "        y_pred_val = clf.predict(X_pca_cv)\n",
    "\n",
    "        training_accuracy =  getAccuracy(y_pred_train, Y_train) \n",
    "        val_accuracy =  getAccuracy(y_pred_val, Y_val) \n",
    "        \n",
    "        if (val_accuracy > best_val_accuracy):\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model = clf\n",
    "        \n",
    "        print(\"For C = \", c, \", Gamma = \", gamma, \": training accuracy = \", training_accuracy, \", val accuracy = \", val_accuracy) \n",
    "        \n",
    "        ta.append(training_accuracy)\n",
    "        va.append(val_accuracy)\n",
    "        \n",
    "    training_accuracies.append(ta)\n",
    "    val_accuracies.append(va)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1700\n",
      "           1       1.00      1.00      1.00      1695\n",
      "\n",
      "    accuracy                           1.00      3395\n",
      "   macro avg       1.00      1.00      1.00      3395\n",
      "weighted avg       1.00      1.00      1.00      3395\n",
      "\n",
      "     pred_neg  pred_pos\n",
      "neg      1700         0\n",
      "pos         1      1694\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "predictions = best_model.predict(X_pca_train)\n",
    "#print(confusion_matrix(Y_test,predictions))\n",
    "print(classification_report(Y_train,predictions))\n",
    "print(pd.DataFrame(confusion_matrix(Y_train,predictions),\n",
    "                 columns=['pred_neg', 'pred_pos'], index=['neg', 'pos']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.84      0.62       170\n",
      "           1       0.45      0.13      0.20       170\n",
      "\n",
      "    accuracy                           0.49       340\n",
      "   macro avg       0.47      0.49      0.41       340\n",
      "weighted avg       0.47      0.49      0.41       340\n",
      "\n",
      "     pred_neg  pred_pos\n",
      "neg       143        27\n",
      "pos       148        22\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "predictions = best_model.predict(X_pca_cv)\n",
    "#print(confusion_matrix(Y_test,predictions))\n",
    "print(classification_report(Y_val,predictions))\n",
    "print(pd.DataFrame(confusion_matrix(Y_val,predictions),\n",
    "                 columns=['pred_neg', 'pred_pos'], index=['neg', 'pos']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy:  0.6705882352941176\n"
     ]
    }
   ],
   "source": [
    "y_scores = clf.predict(X_pca_test)\n",
    "testing_accuracy =  getAccuracy(y_scores, Y_test) \n",
    "print(\"testing accuracy: \", testing_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
